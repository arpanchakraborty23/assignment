{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993f0805-1dcd-4735-8f6d-d98fd41959fe",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52781d78-f457-4a1e-b367-e671ef17dcf8",
   "metadata": {},
   "source": [
    "Lasso is a regression technique that adds an L1 regularization penalty to the ordinary least squares (OLS) objective function. Unlike other regression techniques, Lasso Regression promotes sparsity by setting some coefficients to exactly zero, effectively performing feature selection.\n",
    "\n",
    "cost function= 1/n sumasion(y_actual - y_predict) + lambda sumasion|slop|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a508ef-63de-4904-9a0a-a6ebe4a0ba11",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5c4688b-dabb-42bb-b079-59b61dc0fd3a",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression for feature selection is its ability to automatically select a subset of the most relevant features by setting some coefficients to exactly zero. This promotes sparsity in the model, making it easier to interpret and potentially improving its predictive performance by reducing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0af859-5690-4a99-9855-7ee91074c41f",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13f8ed82-edbc-4614-83f3-67228fa15f58",
   "metadata": {},
   "source": [
    " interpreting the coefficients of a Lasso Regression model involves identifying which predictors have non-zero coefficients, understanding their magnitude and sign, assessing their relative importance, recognizing sparsity-induced feature selection, and gaining insights into the predictors' impact on the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b21a5-41dc-4000-bce7-5b16a1f38d5e",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aed5f7c0-de30-4ec9-913e-970e497ec368",
   "metadata": {},
   "source": [
    "The main tuning parameter in Lasso Regression is the regularization parameter Lambda, which controls the trade-off between model complexity and model fit. Adjusting  Lambda allows for fine-tuning the level of regularization applied to the model\n",
    "\n",
    "1.when dealing with high-dimensional datasets with many irrelevant features.for irrelevant features coefficients being shrunk towards zero lambda should be heigh.\n",
    "\n",
    "2.where preserving all potentially relevant predictors is important, or when dealing with smaller datasets where overfitting is less of a concern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5227b4f-011a-45c5-930f-ee17d9f938f5",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "251213fc-ec61-4db2-8616-425012871caf",
   "metadata": {},
   "source": [
    "Lasso Regression, like other linear regression techniques, is inherently a linear model and is best suited for problems where the relationship between predictors and the target variable is linear. \n",
    "\n",
    "we can create polynomial features by including higher degree of the original predictors. This allows the model to capture non-linear relationships between predictors and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31212a51-1c3e-4552-8265-3e6e1689ace3",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72282e8d-4dfe-4a8a-b83c-678594b3be9c",
   "metadata": {},
   "source": [
    "Ridge Regression and Lasso Regression are both effective regularization techniques that address overfitting in linear regression models. While Ridge Regression is known for reducing multicollinearity and variance, Lasso Regression stands out for its feature selection capabilities .The choice between the two techniques depends on the specific characteristics of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9db7f7-c361-40a7-a1b5-6c4be66f5a21",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cecfeb1c-1976-4302-a35b-3a8df28c0c86",
   "metadata": {},
   "source": [
    "Lasso Regression does not explicitly address multicollinearity by reducing the correlation between predictors, it effectively handles multicollinearity through feature selection and coefficient shrinkage.By automatically selecting a subset of relevant features and setting less important coefficients to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74080ad0-0b7b-4d9b-954d-623b735ec91d",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bcc7f60-86ff-4072-a2e5-37409fd7045e",
   "metadata": {},
   "source": [
    "1.Grid search \n",
    "\n",
    "2. cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd228ac9-5e7c-4641-8ab2-43583f12b16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
