{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomil functions are matamatical expression involving sum of power varible with cofficent with a polinomial degree\n",
    "\n",
    "Kernel functions are used in machine learning algorithms, particularly in SVMs and other kernel methods, to implicitly map data into higher-dimensional feature spaces.\n",
    "\n",
    "polynomial function is base of polynomial krnel\n",
    "Polynomial functions are used to model nonlinear relationships in regresion machine learning\n",
    "\n",
    "Polynomial kernel allow algorithm like svm to perfome in higher-dimensional spaces without explicit computation in those spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step-1 load dataset nesseary libaries\n",
    "\n",
    "step:-2 devide data into dependened and independend vriabels\n",
    "\n",
    "and train_test_split data \n",
    "\n",
    "step:-3 data preprocesssing scale/normalize data \n",
    "\n",
    "step:-4 class svc classifier change kernal liner to poly\n",
    "and fit train data ,predict data\n",
    "\n",
    "step:-5 calculate model accuray if hyperprameter tuning needed then evaluate \n",
    "gridsearchcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Increasing the value of epsilon in SVR generally leads to a wider margin of tolerance for errors. This wider margin typically results in fewer support vectors because the model does not need as many support vectors to define a wider acceptable region around the regression function. Conversely, decreasing epsilon tends to tighten the margin and can lead to more support vectors as the model aims to fit the data more closely within a narrower margin.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "## affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Function: Determines the type of function used to map the input space into a higher-dimensional feature space where linear separation is possible.\n",
    "\n",
    "ex- 1. Linear Kernel: Suitable when the relationship between features and target is approximately linear\n",
    "\n",
    "\t\t2. Polynomial Kernel: Useful for capturing non-linear relationships, with the degree parameter controlling the degree of the polynomial.\n",
    "\n",
    "C Parameter: Penalty parameter that controls achieving a low training error and a smooth decision  boundary.\n",
    "\n",
    "Small C: Allows for a larger margin of tolerance, potentially increasing the number of support vectors and leading to a smoother decision boundary \n",
    "\n",
    "Large C: Penalizes errors more heavily, resulting in a smaller margin and potentially fewer support vectors. This can lead to a more complex decision boundary\n",
    "\n",
    "Epsilon Parameter:Specifies the margin of tolerance where no penalty is given to errors.\n",
    "\n",
    "Small Epsilon: Makes the model more sensitive to errors\n",
    "\n",
    "Large Epsilon: Allows larger deviations from the regression function without penalty, resulting in a larger margin and potentially fewer support vectors.\n",
    "\n",
    "\n",
    "Gamma Parameter Defines how far the influence of a single training example reaches.\n",
    "\n",
    "small Gamma: Results in a smoother decision boundary and larger leads to a more complex decision boundary this can lead to overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "1. Import the necessary libraries and load the dataseg\n",
    "3. Split the dataset into training and testing setZ\n",
    "4. Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "5. Create an instance of the SVC classifier and train it on the training datW\n",
    "6. hse the trained classifier to predict the labels of the testing datW\n",
    "7. Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "8. Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "9. Train the tuned classifier on the entire dataseg\n",
    "10. Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(data.data,columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.26,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>12.060</td>\n",
       "      <td>18.90</td>\n",
       "      <td>76.66</td>\n",
       "      <td>445.3</td>\n",
       "      <td>0.08386</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.00751</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.06048</td>\n",
       "      <td>...</td>\n",
       "      <td>13.640</td>\n",
       "      <td>27.06</td>\n",
       "      <td>86.54</td>\n",
       "      <td>562.6</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.13520</td>\n",
       "      <td>0.04506</td>\n",
       "      <td>0.05093</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.08083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>13.870</td>\n",
       "      <td>16.21</td>\n",
       "      <td>88.52</td>\n",
       "      <td>593.7</td>\n",
       "      <td>0.08743</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.01502</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>25.58</td>\n",
       "      <td>96.74</td>\n",
       "      <td>694.4</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.05285</td>\n",
       "      <td>0.05556</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.07113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>12.560</td>\n",
       "      <td>19.07</td>\n",
       "      <td>81.92</td>\n",
       "      <td>485.8</td>\n",
       "      <td>0.08760</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0.043910</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.06184</td>\n",
       "      <td>...</td>\n",
       "      <td>13.370</td>\n",
       "      <td>22.43</td>\n",
       "      <td>89.02</td>\n",
       "      <td>547.4</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.20020</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.09265</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.07188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>14.260</td>\n",
       "      <td>19.65</td>\n",
       "      <td>97.83</td>\n",
       "      <td>629.9</td>\n",
       "      <td>0.07837</td>\n",
       "      <td>0.22330</td>\n",
       "      <td>0.30030</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.07769</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>23.73</td>\n",
       "      <td>107.00</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.08949</td>\n",
       "      <td>0.41930</td>\n",
       "      <td>0.67830</td>\n",
       "      <td>0.15050</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.10820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.08046</td>\n",
       "      <td>...</td>\n",
       "      <td>10.310</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>18.810</td>\n",
       "      <td>19.98</td>\n",
       "      <td>120.90</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.08923</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.08020</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>...</td>\n",
       "      <td>19.960</td>\n",
       "      <td>24.30</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.05737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9.436</td>\n",
       "      <td>18.32</td>\n",
       "      <td>59.82</td>\n",
       "      <td>278.6</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.02710</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.06959</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>25.02</td>\n",
       "      <td>75.79</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.13330</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>0.05052</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.08136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.720</td>\n",
       "      <td>18.22</td>\n",
       "      <td>60.73</td>\n",
       "      <td>288.1</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>0.06447</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968</td>\n",
       "      <td>20.83</td>\n",
       "      <td>62.25</td>\n",
       "      <td>303.8</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.06559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "346       12.060         18.90           76.66      445.3          0.08386   \n",
       "357       13.870         16.21           88.52      593.7          0.08743   \n",
       "355       12.560         19.07           81.92      485.8          0.08760   \n",
       "112       14.260         19.65           97.83      629.9          0.07837   \n",
       "68         9.029         17.33           58.79      250.5          0.10660   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "277       18.810         19.98          120.90     1102.0          0.08923   \n",
       "9         12.460         24.04           83.97      475.9          0.11860   \n",
       "359        9.436         18.32           59.82      278.6          0.10090   \n",
       "192        9.720         18.22           60.73      288.1          0.06950   \n",
       "559       11.510         23.93           74.52      403.5          0.09261   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "346           0.05794         0.00751             0.008488         0.1555   \n",
       "357           0.05492         0.01502             0.020880         0.1424   \n",
       "355           0.10380         0.10300             0.043910         0.1533   \n",
       "112           0.22330         0.30030             0.077980         0.1704   \n",
       "68            0.14130         0.31300             0.043750         0.2111   \n",
       "..                ...             ...                  ...            ...   \n",
       "277           0.05884         0.08020             0.058430         0.1550   \n",
       "9             0.23960         0.22730             0.085430         0.2030   \n",
       "359           0.05956         0.02710             0.014060         0.1506   \n",
       "192           0.02344         0.00000             0.000000         0.1653   \n",
       "559           0.10210         0.11120             0.041050         0.1388   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "346                 0.06048  ...        13.640          27.06   \n",
       "357                 0.05883  ...        15.110          25.58   \n",
       "355                 0.06184  ...        13.370          22.43   \n",
       "112                 0.07769  ...        15.300          23.73   \n",
       "68                  0.08046  ...        10.310          22.65   \n",
       "..                      ...  ...           ...            ...   \n",
       "277                 0.04996  ...        19.960          24.30   \n",
       "9                   0.08243  ...        15.090          40.68   \n",
       "359                 0.06959  ...        12.020          25.02   \n",
       "192                 0.06447  ...         9.968          20.83   \n",
       "559                 0.06570  ...        12.480          37.16   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "346            86.54       562.6           0.12890            0.13520   \n",
       "357            96.74       694.4           0.11530            0.10080   \n",
       "355            89.02       547.4           0.10960            0.20020   \n",
       "112           107.00       709.0           0.08949            0.41930   \n",
       "68             65.50       324.7           0.14820            0.43650   \n",
       "..               ...         ...               ...                ...   \n",
       "277           129.00      1236.0           0.12430            0.11600   \n",
       "9              97.65       711.4           0.18530            1.05800   \n",
       "359            75.79       439.6           0.13330            0.10490   \n",
       "192            62.25       303.8           0.07117            0.02729   \n",
       "559            82.28       474.2           0.12980            0.25170   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "346          0.04506               0.05093          0.2880   \n",
       "357          0.05285               0.05556          0.2362   \n",
       "355          0.23880               0.09265          0.2121   \n",
       "112          0.67830               0.15050          0.2398   \n",
       "68           1.25200               0.17500          0.4228   \n",
       "..               ...                   ...             ...   \n",
       "277          0.22100               0.12940          0.2567   \n",
       "9            1.10500               0.22100          0.4366   \n",
       "359          0.11440               0.05052          0.2454   \n",
       "192          0.00000               0.00000          0.1909   \n",
       "559          0.36300               0.09653          0.2112   \n",
       "\n",
       "     worst fractal dimension  \n",
       "346                  0.08083  \n",
       "357                  0.07113  \n",
       "355                  0.07188  \n",
       "112                  0.10820  \n",
       "68                   0.11750  \n",
       "..                       ...  \n",
       "277                  0.05737  \n",
       "9                    0.20750  \n",
       "359                  0.08136  \n",
       "192                  0.06559  \n",
       "559                  0.08732  \n",
       "\n",
       "[421 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_obj=Pipeline(\n",
    "    steps=[\n",
    "        ('Impute',SimpleImputer(strategy='median')),\n",
    "        ('outliers',RobustScaler()),\n",
    "        ('Normalize',MinMaxScaler())\n",
    "\t ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocess_obj.pkl','wb')as f:\n",
    "    pickle.dump(preprocess_obj,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc=preprocess_obj.fit_transform(x_train)\n",
    "x_test_sc=preprocess_obj.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train_sc,y_train)\n",
    "y_pred=clf.predict(x_test_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91        55\n",
      "           1       0.92      0.99      0.95        93\n",
      "\n",
      "    accuracy                           0.94       148\n",
      "   macro avg       0.95      0.92      0.93       148\n",
      "weighted avg       0.94      0.94      0.94       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}\n",
    "random=RandomizedSearchCV(clf,param_distributions=param_grid,n_iter=10,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.929 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.929 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=10, kernel=rbf;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .......C=100, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .......C=100, gamma=10, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END .......C=100, gamma=10, kernel=rbf;, score=0.940 total time=   0.0s\n",
      "[CV 5/5] END .......C=100, gamma=10, kernel=rbf;, score=0.929 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.988 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=SVC(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                                        &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;, 0.1, 1, 10],\n",
       "                                        &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=SVC(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
       "                                        &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;, 0.1, 1, 10],\n",
       "                                        &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(),\n",
       "                   param_distributions={'C': [0.1, 1, 10, 100],\n",
       "                                        'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
       "                                        'kernel': ['linear', 'rbf']},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 1, 'C': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(**random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train_sc,y_train)\n",
    "y_pred=clf.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
