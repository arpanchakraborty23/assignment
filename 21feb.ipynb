{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ac457c-0a48-457d-930f-598093bfdb03",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f8c5319-ccf6-46bc-a58b-1ba5ddcbd7e0",
   "metadata": {},
   "source": [
    "\n",
    "Web scraping is the process of automatically extracting information from websites. It involves retrieving the content of web pages, parsing it, and extracting specific data points from it\n",
    "Web scraping is used for a variety of purposes, primarily to gather large amounts of data from the internet that would be time-consuming or impractical to collect manually\n",
    "\n",
    "use: 1.Automates the process of collecting data from websites, making it possible to gather information at scale.\n",
    "        2. Enables businesses to monitor competitors, analyze market trends, and gather insights about industry performance.\n",
    "    3.  Helps businesses track prices across different e-commerce platforms for dynamic pricing strategies."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a97cae06-640c-48b3-96b8-8609f133e0cc",
   "metadata": {},
   "source": [
    "Areas Where Web Scraping is Used\n",
    "1.Web scraping is used to gather pricing information from multiple e-commerce websites to create comparison tools that help consumers find the best deals.\n",
    "2.Retailers use scraping to track competitors' stock levels and adjust their own inventory and pricing strategies accordingly.\n",
    "3. Analysts use scraping to assess real estate market trends by collecting historical data on property sales and rental prices.\n",
    "4. Travel websites use web scraping to collect pricing information from airlines and hotels, enabling them to offer dynamic pricing and competitive deals to customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec96947-c48e-4aab-9ff5-ba53d7d1b191",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aeb2e0bf-848c-4290-9c19-7fefde83dfa0",
   "metadata": {},
   "source": [
    "1. Manual Copy-Pasting:  The most straightforward method involves manually copying and pasting data from websites into a local file or database.This approach is feasible for small-scale tasks or when the volume of data is minimal.\n",
    "\n",
    "2. HTML Parsing Libraries: Libraries like BeautifulSoup (Python) and Cheerio (Node.js) parse HTML and XML documents, allowing for easy navigation and data extraction.\n",
    "\n",
    "3.Regular Expressions: Regular expressions can be used to identify and extract patterns in HTML content. This method is useful for simple scraping tasks where the structure is predictable\n",
    "\n",
    "4. Web Scraping Frameworks: Frameworks like Scrapy provide a robust infrastructure for crawling websites and extracting data efficiently.\n",
    "\n",
    "5. API Access: Many websites offer APIs to provide structured data access, which is often more efficient and ethical than scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dd802-5eb3-44ef-8a25-d7d2476af2aa",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9924280f-d5ab-4c37-91d9-514d83a5cabd",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is particularly useful for web scraping purposes. Beautiful Soup provides Pythonic idioms for iterating, searching, and modifying the parse tree, making it easier to extract and manipulate web data.\n",
    "\n",
    "why use \n",
    "1.Beautiful Soup provides a simple and intuitive interface for navigating and searching HTML/XML parse trees. This makes it accessible to beginners and powerful enough for advanced users.\n",
    "2.The library offers numerous methods for searching through the parse tree using tags, attributes, and CSS selectors, enabling precise extraction of specific data points.\n",
    "3.Beautiful Soup can parse and process poorly structured HTML and XML documents, making it useful for extracting data from web pages with inconsistent markup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc8fd7-48ac-4de9-8d47-10de2d007627",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a3c6f11-7290-4d65-8443-07ddd075b49c",
   "metadata": {},
   "source": [
    "Flask is an excellent choice for web scraping projects because it allows developers to quickly set up a web interface or API for managing and displaying the data. Its lightweight nature and flexibility make it ideal for integrating with web scraping tools and providing users with a seamless way to interact with the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db52b61-abef-449e-82a4-56ca82618a14",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d8161-71f0-4d8d-8da4-93c4b221bc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
