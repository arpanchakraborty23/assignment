{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de29d22e-5f0d-4e74-a70b-e9213bed3701",
   "metadata": {},
   "source": [
    "# Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85bf474f-2ccd-4456-8bca-dcdc9f313e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "Random Forest Regressor is ensemble technique that use bagging method for predict\n",
    "continuous traget variable.\n",
    "\n",
    "alike Random Forest Classifer it use Decision tree Regressor as base learner to predict\n",
    "subset of original dataset. final out put it provide  by taking avarge value of base learner\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900e47f-f3f7-46f2-88cd-98cfcf0bcc14",
   "metadata": {},
   "source": [
    "## Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ae1f7ee-6d46-4eac-a0fa-fe4cc37cfe69",
   "metadata": {},
   "source": [
    "Random Forest use Decision tree as base lerner if we use single Decision tree\n",
    "it splits data untill gets leaf node. during spliting it get's huge the spliting values are almost\n",
    "similr if new data came it did't predict accurate.\n",
    "\n",
    "but if we use subsmple data then it create small trees that can understand complex data easily\n",
    "so, Random Forest is best chioce for avoid overfiiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39316e-e64f-4d61-a92f-dea999f7f903",
   "metadata": {},
   "source": [
    "# Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f1cbd1b-5f87-4355-b048-bb94f8441a55",
   "metadata": {},
   "source": [
    "Boostrap aggrigation:\n",
    "    predictions of multiple decision trees Regressor it add all prediction vlues\n",
    "by taking avarage of sum of all predict value ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f6f35-9e5a-45b6-95b5-3e8613f3699e",
   "metadata": {},
   "source": [
    "# Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb4ed7d8-c9c4-4f36-abc7-cd283e8c9e0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "1.n_estimators: the no of model we want as base learner.\n",
    "\n",
    "2. criterion: formula for taking right atribut for split.\n",
    "\n",
    "3.max_depth : no of split we want for a tree\n",
    "\n",
    "4. oob_score: validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79accc-b34b-4801-bfdf-11f16b47c01d",
   "metadata": {},
   "source": [
    "## Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2973c738-0bea-4108-9903-50c30ac4955d",
   "metadata": {},
   "source": [
    "A Decision Tree Regressor is a single decision tree that is trained on the entire dataset.\n",
    "A Random Forest Regressor is an ensemble of multiple decision trees. Each tree is trained on a random subset of the data.\n",
    "\n",
    "Uses entire dataset\n",
    "Uses bootstrap samples\n",
    "\n",
    "Prone to overfitting\n",
    "Less prone to overfitting due to averaging\n",
    "\n",
    "Lower computational cost\n",
    "Higher computational cost due to training multiple trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d391f-e4f6-4a47-9987-6f0fd8409469",
   "metadata": {},
   "source": [
    "## Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d8b6a03-31e3-4779-9e8c-970d60509257",
   "metadata": {},
   "source": [
    "Advantage:\n",
    "    1. Better performance on larger, complex datasets\n",
    "    2. Less prone to overfitting\n",
    "    3. \tLower variance due to averaging multiple models\n",
    "    \n",
    "Disdvntges:\n",
    "    1. Higher computational cost due to training multiple trees.\n",
    "    2. Time consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e45bb-e6f1-419f-8d53-4d07ac83d328",
   "metadata": {},
   "source": [
    "## Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf02d37-5cbf-4cc5-a490-cf13a4e1e728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1730282657.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    output of Random Forest Regressor is countionus value\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "output of Random Forest Regressor is countionus value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5a229-55e6-4966-b24e-19a5dbed24cf",
   "metadata": {},
   "source": [
    "# Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de4b895c-1bcf-4e1f-9ac1-1182b20d9d1d",
   "metadata": {},
   "source": [
    "Regressor: Used for regression tasks where the target variable is continuous.\n",
    "Classifier: Used for classification tasks where the target variable is categorical.\n",
    "\n",
    "Regressor: Predicts a continuous value.\n",
    "Predicts a class label and can also provide class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe643f74-d30f-477e-83e5-99bd3f784d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
